{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import shap\n",
    "\n",
    "# Load your custom emotion classification model and tokenizer\n",
    "emotion_pipeline = transformers.pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"./emotion_model\",\n",
    "    tokenizer=\"./emotion_model\",\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "# Predict on a single sample\n",
    "sample_text = \"I feel absolutely wonderful today!\"\n",
    "prediction = emotion_pipeline(sample_text)\n",
    "    \n",
    "print(\"Prediction:\", prediction)\n",
    "\n",
    "# Use SHAP for explanations\n",
    "# explainer = shap.Explainer(emotion_pipeline)\n",
    "\n",
    "# # Sample inputs for SHAP explanations\n",
    "# sample_inputs = [\n",
    "#     \"What a great day! I am so happy and full of joy.\",\n",
    "#     \"I am scared to try new things, it makes me nervous.\",\n",
    "#     \"I hate this so much, it's terrible!\"\n",
    "# ]\n",
    "\n",
    "# # Compute SHAP values for the inputs\n",
    "# shap_values = explainer(sample_inputs)\n",
    "\n",
    "# # Select the class index for \"joy\" (replace with the actual index if different)\n",
    "# joy_class_index = 1  # Adjust this based on your model's output\n",
    "\n",
    "# # Visualize the SHAP explanation for the first input\n",
    "# shap.plots.text(shap_values[0, :, joy_class_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"text.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure columns are correctly loaded\n",
    "data.columns = [col.strip() for col in data.columns]\n",
    "\n",
    "# Load spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to extract POS tags from phrases\n",
    "def extract_pos_tags(phrases):\n",
    "    \"\"\"\n",
    "    Extract verbs, adjectives, adverbs, and nouns from a list of phrases using spaCy.\n",
    "    Returns a dictionary with POS tags as keys and their counts as values.\n",
    "    \"\"\"\n",
    "    pos_tags = {\"VERB\": Counter(), \"ADJ\": Counter(), \"ADV\": Counter(), \"NOUN\": Counter()}\n",
    "    \n",
    "    for phrase in phrases:\n",
    "        doc = nlp(phrase)\n",
    "        for token in doc:\n",
    "            if token.pos_ in pos_tags:\n",
    "                pos_tags[token.pos_].update([token.lemma_])  # Use lemma for base form\n",
    "    \n",
    "    return pos_tags\n",
    "\n",
    "# Group phrases by label\n",
    "grouped_data = data.groupby(\"label\")[\"text\"]\n",
    "\n",
    "# Analyze each label\n",
    "label_pos_counts = {}\n",
    "for label, phrases in grouped_data:\n",
    "    print(f\"Processing label: {label}\")\n",
    "    label_pos_counts[label] = extract_pos_tags(phrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display and visualize results\n",
    "for label, pos_counts in label_pos_counts.items():\n",
    "    print(f\"\\nLabel: {label}\")\n",
    "    \n",
    "    # Display most common words by POS tag\n",
    "    for pos, counter in pos_counts.items():\n",
    "        print(f\"  Most common {pos}s:\")\n",
    "        for word, count in counter.most_common(25):\n",
    "            print(f\"    {word}: {count}\")\n",
    "    \n",
    "    # Generate a word cloud for nouns as an example\n",
    "    # wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate_from_frequencies(pos_counts[\"NOUN\"])\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    # plt.axis(\"off\")\n",
    "    # plt.title(f\"Word Cloud for Nouns in Label: {label}\")\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"text.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure columns are correctly loaded\n",
    "data.columns = [col.strip() for col in data.columns]\n",
    "\n",
    "# Count the number of phrases for each label\n",
    "label_counts = data['label'].value_counts()\n",
    "\n",
    "# Tokenize and count word frequencies for each label\n",
    "def clean_and_tokenize(phrase):\n",
    "    \"\"\"Clean text and tokenize.\"\"\"\n",
    "    phrase = re.sub(r\"[^\\w\\s]\", \"\", phrase.lower())  # Remove punctuation and lowercase\n",
    "    return phrase.split()\n",
    "\n",
    "word_frequencies = {label: Counter() for label in label_counts.index}\n",
    "for _, row in data.iterrows():\n",
    "    label = row['label']\n",
    "    words = clean_and_tokenize(row['text'])\n",
    "    word_frequencies[label].update(words)\n",
    "\n",
    "# Calculate mean of positive numbers for each label (if a \"pos\" column exists)\n",
    "if \"pos\" in data.columns:\n",
    "    pos_means = data.groupby(\"label\")[\"pos\"].mean()\n",
    "else:\n",
    "    pos_means = None\n",
    "\n",
    "# Display most common words for each label\n",
    "for label, counter in word_frequencies.items():\n",
    "    print(f\"Most common words for label '{label}':\")\n",
    "    for word, count in counter.most_common(10):\n",
    "        print(f\"  {word}: {count}\")\n",
    "    print()\n",
    "\n",
    "# Display label counts\n",
    "print(\"Number of phrases for each label:\")\n",
    "print(label_counts)\n",
    "\n",
    "# Display mean of positive numbers (if available)\n",
    "if pos_means is not None:\n",
    "    print(\"\\nMean of 'pos' values for each label:\")\n",
    "    print(pos_means)\n",
    "\n",
    "# Generate word clouds for each label\n",
    "for label, counter in word_frequencies.items():\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate_from_frequencies(counter)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Word Cloud for Label: {label}\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
